{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pideq.net import PINN, PIDEQ\n",
    "from pideq.deq.solvers import forward_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PINN(1., n_nodes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3152,  0.4197]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.3152,  0.4197]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "deq = PIDEQ.from_pinn(net)\n",
    "\n",
    "x = torch.rand(1,2)\n",
    "\n",
    "print(net(x[...,0].unsqueeze(-1), x[...,1].unsqueeze(-1)))\n",
    "print(deq(x[...,0].unsqueeze(-1), x[...,1].unsqueeze(-1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define number of states for each hidden layer\n",
    "n_states = 0\n",
    "for l in net.fcn[:-2]:  # exclude ouptut layer\n",
    "    try:\n",
    "        n_states += l.out_features\n",
    "    except AttributeError:\n",
    "        pass\n",
    "n_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIDEQ(\n",
       "  (B): Linear(in_features=12, out_features=12, bias=True)\n",
       "  (A): Linear(in_features=2, out_features=12, bias=True)\n",
       "  (h): Linear(in_features=12, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deq = PIDEQ(1., n_in=net.fcn[0].in_features, n_out=net.fcn[-1].out_features, n_states=n_states, n_hidden=0, solver=forward_iteration)\n",
    "deq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = net.fcn[0]\n",
    "\n",
    "A_w = torch.zeros_like(deq.A.weight)\n",
    "A_w[:l1.weight.shape[0]] = l1.weight\n",
    "deq.A.weight = nn.Parameter(A_w)\n",
    "\n",
    "A_b = torch.zeros_like(deq.A.bias)\n",
    "A_b[:l1.bias.shape[0]] = l1.bias\n",
    "deq.A.bias = nn.Parameter(A_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_w = torch.zeros_like(deq.B.weight)\n",
    "B_b = torch.zeros_like(deq.B.bias)\n",
    "\n",
    "l0 = net.fcn[0].out_features  # end of the last hidden layer's output\n",
    "for l in net.fcn[1:-2]:  # skip first and last layers\n",
    "    if isinstance(l, nn.Linear):\n",
    "        B_w[l0:l0 + l.out_features,l0 - l.in_features:l0] = l.weight\n",
    "        B_b[l0:l0 + l.out_features] = l.bias\n",
    "        l0 = l0 + l.out_features\n",
    "\n",
    "deq.B.weight = nn.Parameter(B_w)\n",
    "deq.B.bias = nn.Parameter(B_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = net.fcn[-1]\n",
    "\n",
    "h_w = torch.zeros_like(deq.h.weight)\n",
    "h_w[:,-ll.weight.shape[-1]:] = ll.weight\n",
    "deq.h.weight = nn.Parameter(h_w)\n",
    "\n",
    "h_b = torch.zeros_like(deq.h.bias)\n",
    "h_b[-ll.bias.shape[0]:] = ll.bias\n",
    "deq.h.bias = nn.Parameter(h_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4703, 0.3210]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = torch.zeros(1,12)\n",
    "z = z0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1996,  0.2331,  0.2224,  0.2395,  0.3311, -0.1186,  0.0319,  0.1266,\n",
       "         -0.2079, -0.1951,  0.2081,  0.1212]], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = deq.nonlin(deq.A(x) + deq.B(z))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3377, 0.1848]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deq.h(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2023,  0.2375,  0.2261]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.1996,  0.2331,  0.2224]], grad_fn=<TanhBackward0>)\n",
      "tensor([[ 0.2443,  0.3440, -0.1191]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.2395,  0.3311, -0.1186]], grad_fn=<TanhBackward0>)\n",
      "tensor([[ 0.0319,  0.1273, -0.2110]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0319,  0.1266, -0.2079]], grad_fn=<TanhBackward0>)\n",
      "tensor([[-0.1976,  0.2112,  0.1218]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.1951,  0.2081,  0.1212]], grad_fn=<TanhBackward0>)\n",
      "tensor([[0.3377, 0.1848]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# z = torch.zeros(1,2)\n",
    "z = x\n",
    "for l in net.fcn:\n",
    "    z = l(z)\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0477, 0.0570], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x[...,0], x[...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0477, 0.0570],\n",
       "         [0.0477, 0.0570]], grad_fn=<AddmmBackward0>),\n",
       " tensor(0.6040, grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deq(x[...,0], x[...,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pideq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76e517517d3f93e7eb9ebf3e50a46788dab0d10ec868053dc585cc83b37e8a32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
